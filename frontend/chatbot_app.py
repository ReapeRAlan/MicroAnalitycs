"""
Frontend para Ollama - Interfaz de Chat para PredicciÃ³n de Demanda
================================================================

AplicaciÃ³n Streamlit que proporciona una interfaz de usuario moderna
para interactuar con el sistema de predicciÃ³n de demanda a travÃ©s de Ollama.
"""

import streamlit as st
import asyncio
import json
import requests
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import sys
import os

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Agregar el directorio padre al path para importar mÃ³dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Importaciones bÃ¡sicas sin Ollama por ahora
try:
    from chatbot.communication_schema import (
        PredictionScope, ModelType, RequestType
    )
    OLLAMA_AVAILABLE = True
except ImportError as e:
    print(f"Ollama integration not available: {e}")
    OLLAMA_AVAILABLE = False
    # Definir enums bÃ¡sicos como fallback
    class PredictionScope:
        SINGLE_PRODUCT = "single_product"
        CATEGORY = "category" 
        BUSINESS = "business"
        MARKET = "market"
    
    class ModelType:
        AUTO_SELECT = "auto_select"
        LINEAR = "linear"
        POLYNOMIAL = "polynomial"


# ConfiguraciÃ³n de la pÃ¡gina
# st.set_page_config(
#     page_title="MicroAnalytics - Chat de PredicciÃ³n",
#     page_icon="ğŸ¤–",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# CSS optimizado para mÃ¡xima legibilidad y contraste


class ChatbotFrontend:
    """Clase principal para el frontend del chatbot"""
    
    def __init__(self):
        self.backend_url = "http://localhost:8000"  # URL del backend FastAPI
        self.session_id = self._get_session_id()
        self.ollama_client = None
        self.interpreter = None
        
        # Inicializar estado de la sesiÃ³n
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []
        if 'current_context' not in st.session_state:
            st.session_state.current_context = {}
        if 'tool_results' not in st.session_state:
            st.session_state.tool_results = {
                'recent_predictions': [],
                'recent_comparisons': [],
                'recent_analysis': [],
                'last_action': None,
                'last_results': None
            }
    
    def _get_session_id(self) -> str:
        """Obtener o crear ID de sesiÃ³n"""
        if 'session_id' not in st.session_state:
            st.session_state.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        return st.session_state.session_id
    
    async def _init_ollama_client(self):
        """Inicializar cliente de Ollama con detecciÃ³n automÃ¡tica de modelos"""
        if not OLLAMA_AVAILABLE:
            logger.warning("Ollama integration no disponible")
            return False
            
        if self.ollama_client is None:
            try:
                from chatbot.ollama_integration import OllamaClient, OllamaConfig
                
                # URL fija de Ollama
                ollama_url = "https://def7-34-145-102-97.ngrok-free.app"
                
                # Crear configuraciÃ³n temporal para detectar modelos
                temp_config = OllamaConfig(
                    base_url=ollama_url,
                    model_name="llama3.2",  # Modelo por defecto
                    timeout=30,
                    max_tokens=1000,
                    temperature=0.7
                )
                
                # Crear cliente temporal
                temp_client = OllamaClient(temp_config)
                
                # Detectar modelos disponibles
                available_models = await self._detect_available_models(temp_client, ollama_url)
                
                if not available_models:
                    logger.warning("No se pudieron detectar modelos en Ollama")
                    return False
                
                # Seleccionar el mejor modelo
                best_model = self._select_best_model(available_models)
                logger.info(f"Usando modelo: {best_model} de {available_models}")
                
                # Crear configuraciÃ³n final
                final_config = OllamaConfig(
                    base_url=ollama_url,
                    model_name=best_model,
                    timeout=120,
                    max_tokens=1000,
                    temperature=0.7
                )
                
                # Crear cliente final
                self.ollama_client = OllamaClient(final_config)
                
                # Verificar conexiÃ³n final
                if await self.ollama_client.check_connection():
                    logger.info(f"Ollama conectado exitosamente con modelo {best_model}")
                    st.session_state.ollama_connected = True
                    st.session_state.ollama_model_used = best_model
                    return True
                else:
                    logger.warning("No se pudo conectar con Ollama")
                    self.ollama_client = None
                    return False
                    
            except ImportError as e:
                logger.error(f"Error importando Ollama (posiblemente falta aiohttp): {e}")
                return False
            except Exception as e:
                logger.error(f"Error inicializando Ollama: {e}")
                self.ollama_client = None
                return False
        
        return True

    async def _detect_available_models(self, client, base_url):
        """Detectar modelos disponibles en Ollama"""
        try:
            # Intentar importar aiohttp
            try:
                import aiohttp
            except ImportError:
                logger.error("aiohttp no estÃ¡ disponible. InstÃ¡lalo con: pip install aiohttp")
                return []
            
            async with aiohttp.ClientSession() as session:
                headers = {
                    "ngrok-skip-browser-warning": "true",
                    "Content-Type": "application/json"
                }
                
                async with session.get(
                    f"{base_url}/api/tags",
                    timeout=aiohttp.ClientTimeout(total=10),
                    headers=headers
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        models = [model.get('name', '').split(':')[0] for model in data.get('models', [])]
                        models = [m for m in models if m]  # Filtrar nombres vacÃ­os
                        logger.info(f"Modelos detectados: {models}")
                        return models
                    else:
                        logger.warning(f"Error al obtener modelos: {response.status}")
                        return []
        except Exception as e:
            logger.error(f"Error detectando modelos: {e}")
            # Fallback con modelos comunes
            return ['llama3.2', 'llama3.1', 'llama3']

    def _select_best_model(self, available_models):
        """Seleccionar el mejor modelo basado en prioridad"""
        # Prioridad de modelos (del mejor al menos preferido)
        priority_models = [
            'llama3.2',
            'llama3.1', 
            'llama3',
            'llama2',
            'codellama',
            'mistral',
            'gemma',
            'phi',
            'qwen'
        ]
        
        # Buscar el primer modelo de la lista de prioridad que estÃ© disponible
        for preferred in priority_models:
            for available in available_models:
                if preferred.lower() in available.lower():
                    return available
        
        # Si no se encuentra ninguno preferido, usar el primero disponible
        if available_models:
            return available_models[0]
        
        # Fallback
        return "llama3.2"
    
    def render_sidebar(self):
        """Renderizar barra lateral con configuraciones"""
        st.sidebar.header("ğŸ¤– ConfiguraciÃ³n del Chat")
        
        with st.sidebar.container():
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
            st.subheader("ğŸ”— Estado de Ollama")
            
            # Estado de conexiÃ³n
            if st.session_state.get('ollama_connected', False):
                st.success(f"âœ… Conectado - Modelo: {st.session_state.get('ollama_model_used', 'N/A')}")
            else:
                st.warning("âš ï¸ No conectado")
            
            # URL de Ollama (fija)
            st.info("ğŸŒ URL: https://def7-34-145-102-97.ngrok-free.app")
            
            # BotÃ³n para reconectar
            if st.button("ğŸ”„ Reconectar Ollama"):
                self.ollama_client = None
                st.session_state.ollama_connected = False
                try:
                    connected = asyncio.run(self._init_ollama_client())
                    if connected:
                        st.success("âœ… Reconectado exitosamente")
                        st.rerun()
                    else:
                        st.error("âŒ Error al reconectar")
                except Exception as e:
                    st.error(f"âŒ Error: {e}")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # ConfiguraciÃ³n de predicciones
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
            st.subheader("ğŸ“Š ConfiguraciÃ³n de Predicciones")
            
            # DÃ­as para predicciÃ³n
            prediction_days = st.slider(
                "DÃ­as a predecir",
                min_value=7,
                max_value=90,
                value=st.session_state.get('prediction_days', 30),
                step=7,
                help="NÃºmero de dÃ­as hacia el futuro para las predicciones"
            )
            st.session_state.prediction_days = prediction_days
            
            # Incluir intervalos de confianza
            include_confidence = st.checkbox(
                "Incluir intervalos de confianza",
                value=st.session_state.get('include_confidence', True),
                help="Mostrar rangos de confianza en las predicciones"
            )
            st.session_state.include_confidence = include_confidence
            
            # Usar cachÃ©
            use_cache = st.checkbox(
                "Usar cachÃ© de modelos",
                value=st.session_state.get('use_cache', True),
                help="Acelerar predicciones usando modelos en cachÃ©"
            )
            st.session_state.use_cache = use_cache
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Historial de predicciones
        st.sidebar.header("ï¿½ Historial")
        
        with st.sidebar.container():
            st.markdown('<div class="sidebar-section">', unsafe_allow_html=True)
            
            # Alcance de predicciÃ³n
            scope_options = {
                "Producto Ãºnico": PredictionScope.SINGLE_PRODUCT,
                "CategorÃ­a": PredictionScope.CATEGORY,
                "Negocio": PredictionScope.BUSINESS,
                "Mercado": PredictionScope.MARKET
            }
            
            selected_scope = st.selectbox(
                "Alcance",
                options=list(scope_options.keys()),
                help="Alcance de la predicciÃ³n"
            )
            st.session_state.prediction_scope = scope_options[selected_scope]
            
            # DÃ­as de predicciÃ³n
            prediction_days = st.slider(
                "DÃ­as a predecir",
                min_value=1,
                max_value=365,
                value=30,
                help="NÃºmero de dÃ­as hacia el futuro"
            )
            st.session_state.prediction_days = prediction_days
            
            # Tipo de modelo
            model_options = {
                "Auto-selecciÃ³n": ModelType.AUTO_SELECT,
                "Lineal": ModelType.LINEAR,
                "Polinomial": ModelType.POLYNOMIAL
            }
            
            selected_model_type = st.selectbox(
                "Tipo de modelo",
                options=list(model_options.keys()),
                help="Modelo de ML a utilizar"
            )
            st.session_state.model_type = model_options[selected_model_type]
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        # Historial de predicciones
        st.sidebar.header("ğŸ“ˆ Historial")
        
        if st.session_state.prediction_history:
            for i, pred in enumerate(st.session_state.prediction_history[-5:]):
                with st.sidebar.expander(f"PredicciÃ³n {i+1}"):
                    st.write(f"**Fecha:** {pred['timestamp']}")
                    st.write(f"**Confianza:** {pred['confidence']:.1%}")
                    st.write(f"**Modelo:** {pred['model']}")
        else:
            st.sidebar.info("No hay predicciones aÃºn")
        
        # Limpiar historial
        if st.sidebar.button("ğŸ—‘ï¸ Limpiar Chat"):
            st.session_state.messages = []
            st.session_state.prediction_history = []
            st.rerun()
    
    def render_chat_interface(self):
        """Renderizar interfaz principal de chat"""
        st.header("ğŸ¤– Asistente de PredicciÃ³n de Demanda")
        st.markdown("Pregunta sobre predicciones, anÃ¡lisis de tendencias y insights de tu negocio.")
        
        # Contenedor para mensajes
        chat_container = st.container()
        
        with chat_container:
            # Mostrar historial de mensajes
            for message in st.session_state.messages:
                self._render_message(message)
        
        # Input para nuevos mensajes
        user_input = st.chat_input("Escribe tu pregunta sobre predicciÃ³n de demanda...")
        
        if user_input:
            # Agregar mensaje del usuario
            st.session_state.messages.append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now()
            })
            
            # Procesar mensaje
            with st.spinner("Analizando y generando respuesta..."):
                response = self._process_user_message(user_input)
            
            # Agregar respuesta del asistente
            st.session_state.messages.append({
                "role": "assistant",
                "content": response,
                "timestamp": datetime.now()
            })
            
            st.rerun()
    
    def _render_message(self, message: Dict[str, Any]):
        """Renderizar un mensaje individual"""
        timestamp = message['timestamp'].strftime("%H:%M")
        
        if message['role'] == 'user':
            st.markdown(f"""
            <div class="stChatMessage user-message">
                <strong>TÃº ({timestamp}):</strong> {message['content']}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="stChatMessage assistant-message">
                <strong>Asistente ({timestamp}):</strong> {message['content']}
            </div>
            """, unsafe_allow_html=True)
            
            # Si hay datos de predicciÃ³n, mostrar visualizaciÃ³n
            if 'prediction_data' in message:
                self._render_prediction_visualization(message['prediction_data'])
    
    def _render_prediction_visualization(self, prediction_data: Dict[str, Any]):
        """Renderizar visualizaciÃ³n de predicciÃ³n"""
        try:
            if not prediction_data or 'predicciones' not in prediction_data:
                return
            
            # Crear grÃ¡fico simple con Plotly
            import plotly.graph_objects as go
            
            predicciones = prediction_data.get('predicciones', [])
            if not predicciones:
                return
                
            dias = list(range(1, len(predicciones) + 1))
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=dias,
                y=predicciones,
                mode='lines+markers',
                name='PredicciÃ³n',
                line=dict(color='#1976d2', width=3),
                marker=dict(size=6)
            ))
            
            fig.update_layout(
                title=f"PredicciÃ³n para Producto {prediction_data.get('producto_id', 'N/A')}",
                xaxis_title="DÃ­as",
                yaxis_title="Demanda",
                height=400,
                template="plotly_white"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            logger.warning(f"Error renderizando visualizaciÃ³n: {e}")

    def _process_user_message(self, user_input: str) -> str:
        """Procesar mensaje del usuario y generar respuesta"""
        
        # Intentar inicializar Ollama si no estÃ¡ disponible
        if not self.ollama_client and OLLAMA_AVAILABLE:
            try:
                # Usar asyncio.run para la inicializaciÃ³n
                asyncio.run(self._init_ollama_client())
            except Exception as e:
                logger.warning(f"No se pudo inicializar Ollama: {e}")
        
        # PRIMERO: Detectar si es una pregunta de seguimiento
        if self._detect_follow_up_question(user_input):
            logger.info(f"Pregunta de seguimiento detectada: {user_input}")
            return self._get_contextual_response(user_input)
        
        # SEGUNDO: Detectar intenciÃ³n del usuario para nuevas consultas
        intent = self._detect_intent(user_input)
        
        logger.info(f"Intent detectado: {intent} para input: {user_input}")
        
        # Manejar segÃºn la intenciÃ³n
        if intent == 'prediction':
            return self._handle_prediction_request(user_input)
        elif intent == 'comparison':
            return self._handle_model_comparison(user_input)
        elif intent == 'analysis':
            return self._handle_analysis_request(user_input)
        else:  # general
            return self._handle_general_chat(user_input)
    
    def _detect_intent(self, user_input: str) -> str:
        """Detectar la intenciÃ³n del usuario de manera mÃ¡s inteligente"""
        user_input_lower = user_input.lower()
        
        # Palabras clave mÃ¡s especÃ­ficas para cada intenciÃ³n
        prediction_keywords = [
            'predecir', 'predicciÃ³n', 'pronÃ³stico', 'demanda', 'ventas futuras', 'futuro',
            'prÃ³ximos', 'dÃ­as', 'semanas', 'meses', 'cuÃ¡nto', 'cuÃ¡ntos',
            'producto', 'cuÃ¡l serÃ¡', 'cuanto voy a vender', 'proyecciÃ³n',
            'estimaciÃ³n', 'forecast', 'prever', 'proyectar'
        ]
        
        # Palabras especÃ­ficas para comparaciÃ³n (mÃ¡s restrictivas)
        comparison_keywords = [
            'comparar modelos', 'mejor modelo', 'quÃ© modelo', 'cuÃ¡l modelo',
            'modelo mÃ¡s preciso', 'modelo mÃ¡s exacto', 'accuracy', 'precisiÃ³n del modelo',
            'performance modelo', 'rendimiento modelo', 'evaluar modelos',
            'algoritmo mejor', 'ml accuracy', 'que modelo es mejor', 'cual modelo es mejor',
            'modelo mejor', 'mejores modelos', 'compara modelos'
        ]
        
        # Palabras para anÃ¡lisis de tendencias
        analysis_keywords = [
            'analizar tendencia', 'tendencia de ventas', 'patrÃ³n', 'insight',
            'estudiar', 'examinar tendencia', 'revisar tendencia', 'investigar patrÃ³n',
            'reportar tendencia', 'reporte', 'anÃ¡lisis histÃ³rico', 'comportamiento',
            'categorÃ­a', 'anÃ¡lisis de categorÃ­a'
        ]
        
        # ConversaciÃ³n general
        general_keywords = [
            'hola', 'buenos', 'buenas', 'hey', 'hi', 'hello', 'quÃ© haces',
            'que haces', 'gracias', 'thanks', 'ayuda', 'help', 'quÃ© puedes',
            'capacidades', 'como funciona', 'cÃ³mo funciona'
        ]
        
        # DetecciÃ³n especÃ­fica por frases exactas (mayor prioridad)
        comparison_phrases = [
            'comparar modelos', 'quÃ© modelo', 'cuÃ¡l modelo', 'mejor modelo',
            'que modelo es mejor', 'cual modelo es mejor', 'modelo mejor',
            'mejores modelos', 'compara modelos'
        ]
        
        if any(phrase in user_input_lower for phrase in comparison_phrases):
            return 'comparison'
        
        if any(phrase in user_input_lower for phrase in ['analizar tendencia', 'tendencia de', 'anÃ¡lisis de']):
            return 'analysis'
        
        # Buscar con nÃºmeros de producto (indica predicciÃ³n)
        import re
        if re.search(r'producto\s+\d+', user_input_lower) or re.search(r'\d+\s+dÃ­as?', user_input_lower):
            return 'prediction'
        
        if re.search(r'demanda.*producto', user_input_lower) or re.search(r'cuÃ¡l serÃ¡.*demanda', user_input_lower):
            return 'prediction'
        
        # Contar coincidencias por categorÃ­a
        prediction_count = sum(1 for keyword in prediction_keywords if keyword in user_input_lower)
        comparison_count = sum(1 for keyword in comparison_keywords if keyword in user_input_lower)
        analysis_count = sum(1 for keyword in analysis_keywords if keyword in user_input_lower)
        general_count = sum(1 for keyword in general_keywords if keyword in user_input_lower)
        
        # Decidir basado en la mayor cantidad de coincidencias
        counts = {
            'prediction': prediction_count,
            'comparison': comparison_count,
            'analysis': analysis_count,
            'general': general_count
        }
        
        max_count = max(counts.values())
        if max_count == 0:
            return 'general'  # Si no hay coincidencias claras, asumir conversaciÃ³n general
        
        # Retornar la intenciÃ³n con mÃ¡s coincidencias
        for intent, count in counts.items():
            if count == max_count:
                return intent
        
        return 'general'
    
    def _extract_product_id(self, user_input: str) -> int:
        """Extraer ID de producto del input del usuario"""
        import re
        
        # Buscar patrones como "producto 1", "producto X", etc.
        product_match = re.search(r'producto\s+(\d+)', user_input.lower())
        if product_match:
            return int(product_match.group(1))
        
        # Buscar nÃºmeros directos en el texto
        number_match = re.search(r'\b(\d+)\b', user_input)
        if number_match:
            return int(number_match.group(1))
        
        # Si no encuentra un ID especÃ­fico, usar un ID por defecto basado en contexto
        user_lower = user_input.lower()
        if 'ropa' in user_lower or 'textil' in user_lower:
            return 1
        elif 'electronica' in user_lower or 'computadora' in user_lower:
            return 2
        elif 'comida' in user_lower or 'alimento' in user_lower:
            return 3
        elif 'hogar' in user_lower or 'casa' in user_lower:
            return 4
        elif 'deporte' in user_lower or 'fitness' in user_lower:
            return 5
        else:
            return 1  # ID por defecto

    def _save_tool_result(self, tool_type: str, result_data: Dict[str, Any], user_input: str):
        """Guardar resultados de herramientas para contexto futuro"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if tool_type == 'prediction':
            prediction_summary = {
                'timestamp': timestamp,
                'user_query': user_input,
                'producto_id': result_data.get('producto_id', 'N/A'),
                'prediccion_promedio': result_data.get('predicciones', [0])[-1] if result_data.get('predicciones') else 0,
                'modelo_usado': result_data.get('mejor_modelo', 'N/A'),
                'confianza': result_data.get('confianza', 0),
                'tendencia': result_data.get('trend_type', 'N/A'),
                'raw_data': result_data
            }
            st.session_state.tool_results['recent_predictions'].append(prediction_summary)
            # Mantener solo las Ãºltimas 3
            if len(st.session_state.tool_results['recent_predictions']) > 3:
                st.session_state.tool_results['recent_predictions'].pop(0)
        
        elif tool_type == 'comparison':
            comparison_summary = {
                'timestamp': timestamp,
                'user_query': user_input,
                'mejor_modelo': result_data.get('best_model', 'Random Forest'),
                'r2_scores': result_data.get('r2_scores', {}),
                'conclusion': result_data.get('conclusion', 'ComparaciÃ³n realizada'),
                'raw_data': result_data
            }
            st.session_state.tool_results['recent_comparisons'].append(comparison_summary)
            # Mantener solo las Ãºltimas 2
            if len(st.session_state.tool_results['recent_comparisons']) > 2:
                st.session_state.tool_results['recent_comparisons'].pop(0)
        
        elif tool_type == 'analysis':
            analysis_summary = {
                'timestamp': timestamp,
                'user_query': user_input,
                'tipo_analisis': result_data.get('analysis_type', 'general'),
                'categoria': result_data.get('category', 'N/A'),
                'insights': result_data.get('insights', []),
                'raw_data': result_data
            }
            st.session_state.tool_results['recent_analysis'].append(analysis_summary)
            # Mantener solo las Ãºltimas 2
            if len(st.session_state.tool_results['recent_analysis']) > 2:
                st.session_state.tool_results['recent_analysis'].pop(0)
        
        # Actualizar Ãºltimo resultado
        st.session_state.tool_results['last_action'] = tool_type
        st.session_state.tool_results['last_results'] = result_data

    def _detect_follow_up_question(self, user_input: str) -> bool:
        """Detectar si es una pregunta de seguimiento sobre resultados anteriores"""
        follow_up_patterns = [
            'quÃ© puedes decir al respecto',
            'quÃ© opinas sobre esto',
            'quÃ© significa esto',
            'explÃ­came esto',
            'analiza esto',
            'interpreta esto',
            'quÃ© conclusiones',
            'quÃ© recomendaciones',
            'basÃ¡ndote en esto',
            'sobre estos resultados',
            'sobre esta informaciÃ³n',
            'que me dices de',
            'cÃ³mo interpretas',
            'quÃ© piensas',
            'ejecuta el comando',
            'ejecuta eso',
            'hazlo',
            'ejecutalo',
            'realiza el comando',
            'corre el comando',
            'ejecuta para ver',
            'muestra el resultado',
            'dame los resultados'
        ]
        
        user_lower = user_input.lower()
        return any(pattern in user_lower for pattern in follow_up_patterns)

    def _get_contextual_response(self, user_input: str) -> str:
        """Generar respuesta contextual basada en resultados anteriores"""
        last_action = st.session_state.tool_results.get('last_action')
        last_results = st.session_state.tool_results.get('last_results')
        
        user_lower = user_input.lower()
        
        # Si el usuario pide ejecutar algo y no hay contexto previo, ejecutar herramienta apropiada
        if any(cmd in user_lower for cmd in ['ejecuta', 'ejecutalo', 'hazlo', 'muestra', 'realiza']):
            # Determinar quÃ© ejecutar basado en el contexto de mensajes anteriores
            recent_messages = st.session_state.messages[-3:] if len(st.session_state.messages) >= 3 else st.session_state.messages
            
            for msg in reversed(recent_messages):
                if msg['role'] == 'user':
                    # Si el mensaje anterior mencionaba comparaciÃ³n
                    if any(word in msg['content'].lower() for word in ['modelo', 'comparar', 'mejor', 'preciso']):
                        return self._handle_model_comparison(f"comparar modelos para {msg['content']}")
                    # Si mencionaba anÃ¡lisis de categorÃ­a
                    elif any(word in msg['content'].lower() for word in ['ropa', 'tendencia', 'espera', 'categoria']):
                        return self._handle_analysis_request(msg['content'])
                    # Si mencionaba predicciÃ³n
                    elif any(word in msg['content'].lower() for word in ['predic', 'demanda', 'futuro', 'venta']):
                        return self._handle_prediction_request(msg['content'])
        
        # Si hay contexto previo, analizarlo
        if not last_action or not last_results:
            return self._get_intelligent_fallback(user_input)
        
        if last_action == 'comparison':
            return self._analyze_model_comparison_context(user_input, last_results)
        elif last_action == 'prediction':
            return self._analyze_prediction_context(user_input, last_results)
        elif last_action == 'analysis':
            return self._analyze_analysis_context(user_input, last_results)
        
        return self._get_intelligent_fallback(user_input)

    def _analyze_model_comparison_context(self, user_input: str, comparison_data: Dict) -> str:
        """Analizar y explicar resultados de comparaciÃ³n de modelos"""
        try:
            # Obtener el Ãºltimo resultado de comparaciÃ³n
            recent_comp = st.session_state.tool_results['recent_comparisons'][-1] if st.session_state.tool_results['recent_comparisons'] else None
            
            if not recent_comp:
                return "No encontrÃ© resultados de comparaciÃ³n recientes para analizar."
            
            response = f"""
            <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #7b1fa2; color: #000000;">
            
            ## ğŸ¤” AnÃ¡lisis de la ComparaciÃ³n de Modelos
            
            **BasÃ¡ndome en tu pregunta:** "{user_input}"
            
            ### ğŸ¯ InterpretaciÃ³n de Resultados
            
            <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #4caf50; color: #1b5e20; font-weight: 600;">
            ğŸ† **Modelo Ganador:** {recent_comp['mejor_modelo']}
            </div>
            
            ### ğŸ“Š Â¿QuÃ© significan estos nÃºmeros?
            
            **RÂ² Score (Coeficiente de DeterminaciÃ³n):**
            - ğŸ“ˆ Mide quÃ© tan bien el modelo explica la variabilidad de tus datos
            - ğŸ¯ Rango: 0.0 (terrible) a 1.0 (perfecto)
            - âœ… **Mayor RÂ² = Mejor predicciÃ³n**
            
            **MSE (Error CuadrÃ¡tico Medio):**
            - ğŸ“‰ Promedio de errores al cuadrado
            - ğŸ¯ **Menor MSE = Mejor precisiÃ³n**
            
            **MAE (Error Absoluto Medio):**
            - ğŸ“Š Error promedio sin elevar al cuadrado
            - ğŸ¯ **Menor MAE = Predicciones mÃ¡s cercanas**
            
            ### ğŸ’¡ Recomendaciones PrÃ¡cticas
            
            <div style="background-color: #f3e5f5; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #9c27b0; color: #4a148c; font-weight: 600;">
            ğŸš€ **Para tu negocio:** El {recent_comp['mejor_modelo']} te darÃ¡ las predicciones mÃ¡s confiables
            </div>
            
            **PrÃ³ximos pasos sugeridos:**
            1. ğŸ“Š Usa el {recent_comp['mejor_modelo']} para predicciones futuras
            2. ğŸ”„ Re-evalÃºa mensualmente con nuevos datos
            3. ğŸ“ˆ Monitora la precisiÃ³n en la prÃ¡ctica
            
            ### ğŸ¤– Â¿Quieres que realice algÃºn anÃ¡lisis especÃ­fico?
            
            Puedo ayudarte con:
            - ğŸ“Š PredicciÃ³n de demanda usando el mejor modelo
            - ğŸ“ˆ AnÃ¡lisis de tendencias especÃ­ficas
            - ğŸ¯ Recomendaciones personalizadas para tu inventario
            
            </div>
            """
            
            return response
            
        except Exception as e:
            return f"Error analizando la comparaciÃ³n: {str(e)}"

    def _analyze_prediction_context(self, user_input: str, prediction_data: Dict) -> str:
        """Analizar y explicar resultados de predicciÃ³n"""
        try:
            recent_pred = st.session_state.tool_results['recent_predictions'][-1] if st.session_state.tool_results['recent_predictions'] else None
            
            if not recent_pred:
                return "No encontrÃ© predicciones recientes para analizar."
            
            response = f"""
            <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #1976d2; color: #000000;">
            
            ## ğŸ“Š AnÃ¡lisis de tu PredicciÃ³n de Demanda
            
            **Respondiendo a:** "{user_input}"
            
            ### ğŸ¯ Resumen de Resultados
            
            <div style="background-color: #e3f2fd; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #1976d2; color: #0d47a1; font-weight: 600;">
            ğŸ“¦ **Producto {recent_pred['producto_id']}:** {recent_pred['prediccion_promedio']:.1f} unidades promedio
            </div>
            
            ### ğŸ” InterpretaciÃ³n Detallada
            
            **Confianza del Modelo:**
            - ğŸ¯ **{recent_pred['confianza']:.1%}** de confianza en la predicciÃ³n
            - ğŸ¤– Modelo usado: **{recent_pred['modelo_usado']}**
            - ğŸ“ˆ Tendencia detectada: **{recent_pred['tendencia']}**
            
            ### ğŸ’¡ Â¿QuÃ© significa para tu negocio?
            
            **PlanificaciÃ³n de Inventario:**
            """
            
            # Agregar recomendaciones basadas en la predicciÃ³n
            prediccion = recent_pred['prediccion_promedio']
            if prediccion > 100:
                response += """
            <div style="background-color: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #ff9800; color: #e65100; font-weight: 600;">
            ğŸ”¥ **Alta demanda proyectada** - Considera aumentar tu inventario
            </div>
            """
            elif prediccion > 50:
                response += """
            <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #4caf50; color: #1b5e20; font-weight: 600;">
            âœ… **Demanda moderada** - MantÃ©n niveles de stock normales
            </div>
            """
            else:
                response += """
            <div style="background-color: #fce4ec; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #e91e63; color: #880e4f; font-weight: 600;">
            ğŸ“‰ **Demanda baja** - EvalÃºa promociones o reducir inventario
            </div>
            """
            
            response += f"""
            ### ğŸ“‹ Acciones Recomendadas
            
            1. ğŸ“Š **Stock Ã³ptimo:** {prediccion * 1.2:.0f} unidades (20% buffer)
            2. ğŸ”„ **Punto de reorden:** {prediccion * 0.3:.0f} unidades
            3. ğŸ“… **PrÃ³xima revisiÃ³n:** En 1 semana
            
            ### ğŸ¤– Â¿Te ayudo con algo mÃ¡s?
            
            Puedo ayudarte a:
            - ğŸ” Comparar con otros productos
            - ğŸ“ˆ Analizar tendencias histÃ³ricas
            - ğŸ’° Calcular rentabilidad proyectada
            
            </div>
            """
            
            return response
            
        except Exception as e:
            return f"Error analizando la predicciÃ³n: {str(e)}"

    def _analyze_analysis_context(self, user_input: str, analysis_data: Dict) -> str:
        """Analizar y explicar resultados de anÃ¡lisis general"""
        try:
            recent_analysis = st.session_state.tool_results['recent_analysis'][-1] if st.session_state.tool_results['recent_analysis'] else None
            
            if not recent_analysis:
                return "No encontrÃ© anÃ¡lisis recientes para interpretar."
            
            response = f"""
            <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #ff9800; color: #000000;">
            
            ## ğŸ“ˆ InterpretaciÃ³n del AnÃ¡lisis
            
            **Tu consulta:** "{user_input}"
            
            ### ğŸ¯ Resumen del AnÃ¡lisis Realizado
            
            <div style="background-color: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #ff9800; color: #e65100; font-weight: 600;">
            ğŸ“Š **Tipo:** {recent_analysis['tipo_analisis']} | **CategorÃ­a:** {recent_analysis['categoria']}
            </div>
            
            ### ğŸ’¡ Insights Clave
            """
            
            for insight in recent_analysis.get('insights', [])[:3]:  # Mostrar mÃ¡ximo 3
                response += f"""
            - ğŸ¯ {insight}
            """
            
            response += """
            
            ### ğŸš€ PrÃ³ximos Pasos Sugeridos
            
            1. ğŸ“Š Monitorear tendencias identificadas
            2. ğŸ”„ Ajustar estrategias segÃºn insights
            3. ğŸ“ˆ Revisar resultados en 2 semanas
            
            ### ğŸ¤– Â¿Necesitas mÃ¡s detalles?
            
            Puedo profundizar en:
            - ğŸ“Š AnÃ¡lisis especÃ­ficos por producto
            - ğŸ” Comparaciones detalladas
            - ğŸ’¡ Recomendaciones personalizadas
            
            </div>
            """
            
            return response
            
        except Exception as e:
            return f"Error analizando el anÃ¡lisis: {str(e)}"

    def _handle_prediction_request(self, user_input: str) -> str:
        """Manejar solicitud de predicciÃ³n"""
        try:
            # Extraer parÃ¡metros de la sesiÃ³n
            product_id = self._extract_product_id(user_input)
            
            # Crear peticiÃ³n (formato compatible con backend)
            request_data = {
                "producto_id": product_id,
                "dias_adelante": st.session_state.get('prediction_days', 30),
                "include_confidence": True,
                "use_cache": True
            }
            
            # Intentar llamar al backend
            try:
                response = requests.post(
                    f"{self.backend_url}/api/predict/demanda",
                    json=request_data,
                    timeout=5  # Timeout corto para demo
                )
                
                if response.status_code == 200:
                    prediction_data = response.json()
                    
                    # Guardar en historial
                    st.session_state.prediction_history.append({
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "confidence": prediction_data.get('confianza', 0),
                        "model": prediction_data.get('mejor_modelo', 'unknown'),
                        "data": prediction_data
                    })
                    
                    # Guardar resultado para contexto futuro
                    self._save_tool_result('prediction', prediction_data, user_input)
                    
                    # Generar respuesta interpretativa
                    return self._generate_prediction_interpretation(prediction_data, user_input)
                else:
                    # Backend responde pero hay error, usar datos simulados
                    return self._generate_demo_prediction(product_id, user_input)
                    
            except (requests.RequestException, requests.Timeout):
                # Backend no disponible, usar datos simulados
                return self._generate_demo_prediction(product_id, user_input)
                
        except Exception as e:
            return f"Error procesando predicciÃ³n: {str(e)}"
    
    def _generate_demo_prediction(self, product_id: int, user_input: str) -> str:
        """Generar predicciÃ³n de demostraciÃ³n cuando el backend no estÃ¡ disponible"""
        import numpy as np
        import hashlib
        
        # Usar hash del input para generar datos Ãºnicos pero consistentes
        seed_value = int(hashlib.md5(f"{product_id}_{user_input}".encode()).hexdigest()[:8], 16) % 10000
        np.random.seed(seed_value)
        
        days = st.session_state.get('prediction_days', 30)
        
        # Crear predicciÃ³n simulada mÃ¡s variada
        base_demand = 30 + (product_id % 20) * 5 + np.random.randint(-10, 20)
        
        # Diferentes tipos de tendencia basados en el producto
        trend_types = ['creciente', 'decreciente', 'estacional', 'estable']
        trend_type = trend_types[product_id % 4]
        
        predicted_values = []
        for i in range(days):
            if trend_type == 'creciente':
                trend_value = base_demand + (i * 0.5) + np.random.normal(0, 2)
            elif trend_type == 'decreciente':
                trend_value = base_demand - (i * 0.3) + np.random.normal(0, 2)
            elif trend_type == 'estacional':
                # PatrÃ³n semanal
                seasonal = 15 * np.sin(2 * np.pi * i / 7) + 5 * np.cos(2 * np.pi * i / 14)
                trend_value = base_demand + seasonal + np.random.normal(0, 3)
            else:  # estable
                trend_value = base_demand + np.random.normal(0, 4)
            
            value = max(1, int(trend_value))
            predicted_values.append(value)
        
        # Calcular mÃ©tricas mÃ¡s realistas
        avg_demand = np.mean(predicted_values)
        trend = trend_type
        
        # Confidence basada en tipo de tendencia
        confidence_base = {
            'estable': 0.85,
            'creciente': 0.78,
            'decreciente': 0.72,
            'estacional': 0.68
        }
        
        confidence = confidence_base[trend_type] + np.random.uniform(-0.08, 0.08)
        confidence = max(0.6, min(0.95, confidence))
        
        # Seleccionar modelo basado en tendencia
        model_selection = {
            'estable': 'linear',
            'creciente': 'linear', 
            'decreciente': 'polynomial',
            'estacional': 'random_forest'
        }
        
        selected_model = model_selection[trend_type]
        
        prediction_data = {
            'predicciones': predicted_values,
            'confianza': confidence,
            'mejor_modelo': selected_model,
            'dias_adelante': days,
            'producto_id': product_id,
            'trend_type': trend_type
        }
        
        # Guardar resultados en el contexto de herramientas
        self._save_tool_result('prediction', prediction_data, user_input)
        
        # Guardar en historial
        st.session_state.prediction_history.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "confidence": confidence,
            "model": selected_model,
            "trend": trend_type,
            "data": prediction_data
        })
        
        # Agregar nota de demostraciÃ³n
        demo_note = "ğŸ“ **Modo Demo**: Datos simulados (backend en desarrollo)"
        interpretation = self._generate_prediction_interpretation(prediction_data, user_input)
        
        return f"{demo_note}\n\n{interpretation}"

    def _generate_prediction_interpretation(self, prediction_data: Dict[str, Any], user_input: str) -> str:
        """Generar interpretaciÃ³n detallada de la predicciÃ³n"""
        try:
            product_id = prediction_data.get('producto_id', 'N/A')
            predictions = prediction_data.get('predicciones', [])
            confidence = prediction_data.get('confianza', 0)
            model = prediction_data.get('mejor_modelo', 'unknown')
            trend_type = prediction_data.get('trend_type', 'unknown')
            days = prediction_data.get('dias_adelante', 30)
            
            if not predictions:
                return "No se pudieron generar predicciones para este producto."
            
            avg_demand = sum(predictions) / len(predictions)
            max_demand = max(predictions)
            min_demand = min(predictions)
            
            # Determinar tendencia visual
            if len(predictions) >= 7:
                early_avg = sum(predictions[:7]) / 7
                late_avg = sum(predictions[-7:]) / 7
                trend_direction = "creciente" if late_avg > early_avg * 1.1 else "decreciente" if late_avg < early_avg * 0.9 else "estable"
            else:
                trend_direction = trend_type
            
            response = f"""
            <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #1976d2; color: #000000;">
            
            ## ğŸ“Š PredicciÃ³n de Demanda - Producto {product_id}
            
            **Consulta:** "{user_input}"
            
            ### ğŸ¯ Resumen Ejecutivo
            
            <div style="background-color: #e3f2fd; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #1976d2; color: #0d47a1; font-weight: 600;">
            ğŸ“¦ **Demanda promedio**: {avg_demand:.1f} unidades diarias
            </div>
            
            ### ğŸ“ˆ MÃ©tricas Clave
            
            - ğŸ¯ **Confianza del modelo**: {confidence:.1%}
            - ğŸ¤– **Modelo utilizado**: {model.title()}
            - ğŸ“Š **PerÃ­odo analizado**: {days} dÃ­as
            - ğŸ“ˆ **Tendencia**: {trend_direction.title()}
            - ğŸ“Š **Rango**: {min_demand:.0f} - {max_demand:.0f} unidades
            
            ### ğŸ’¡ InterpretaciÃ³n de Resultados
            
            """
            
            # Recomendaciones basadas en la demanda promedio
            if avg_demand > 100:
                response += """
            <div style="background-color: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #ff9800; color: #e65100; font-weight: 600;">
            ğŸ”¥ **Alta Demanda Proyectada** - Este producto muestra excelente potencial de ventas
            </div>
            
            **Estrategia recomendada:**
            - ğŸ“ˆ **Aumentar inventario** inmediatamente
            - ğŸ¯ **Stock objetivo**: {int(avg_demand * 1.5):.0f} unidades diarias
            - ğŸ”„ **Punto de reorden**: {int(avg_demand * 0.7):.0f} unidades
            """
            elif avg_demand > 50:
                response += """
            <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #4caf50; color: #1b5e20; font-weight: 600;">
            âœ… **Demanda Moderada** - MantÃ©n niveles de stock normales
            </div>
            
            **Estrategia recomendada:**
            - ğŸ“Š **Mantener niveles actuales** de inventario
            - ğŸ¯ **Stock objetivo**: {int(avg_demand * 1.3):.0f} unidades diarias
            - ğŸ”„ **Punto de reorden**: {int(avg_demand * 0.5):.0f} unidades
            """
            else:
                response += """
            <div style="background-color: #fce4ec; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #e91e63; color: #880e4f; font-weight: 600;">
            ğŸ“‰ **Demanda Baja** - EvalÃºa promociones o reducir inventario
            </div>
            
            **Estrategia recomendada:**
            - ğŸ¯ **Evaluar promociones** o descuentos
            - ğŸ“¦ **Reducir inventario** gradualmente
            - ğŸ” **Investigar** factores que afectan la demanda
            """
            
            # Recomendaciones basadas en tendencia
            if trend_direction == "creciente":
                response += """
            - ğŸ“ˆ **Tendencia creciente**: PrepÃ¡rate para mayor demanda
            - ğŸš€ **Oportunidad**: Considera expandir la lÃ­nea de productos similares
            """
            elif trend_direction == "decreciente":
                response += """
            - ğŸ“‰ **Tendencia decreciente**: Ajusta estrategias de marketing
            - ğŸ”„ **AcciÃ³n**: EvalÃºa factores estacionales o competencia
            """
            else:
                response += """
            - ğŸ“Š **Tendencia estable**: Demanda predecible y confiable
            - âœ… **Ventaja**: FÃ¡cil planificaciÃ³n de inventario
            """
            
            response += f"""
            
            ### ğŸ“‹ Plan de AcciÃ³n Recomendado
            
            1. **ğŸ“Š Monitoreo semanal** de las ventas reales vs predicciÃ³n
            2. **ğŸ”„ Ajuste de inventario** segÃºn la tendencia observada
            3. **ğŸ“… RevisiÃ³n en 2 semanas** para evaluar precisiÃ³n del modelo
            4. **ğŸ¯ OptimizaciÃ³n** basada en los resultados obtenidos
            
            ### ğŸ¤– Â¿Necesitas mÃ¡s anÃ¡lisis?
            
            Puedo ayudarte con:
            - ğŸ” **Comparar con otros productos** de tu inventario
            - ğŸ“ˆ **Analizar tendencias** por categorÃ­a
            - ğŸ’° **Calcular rentabilidad** proyectada
            
            </div>
            """
            
            return response
            
        except Exception as e:
            return f"Error generando interpretaciÃ³n de predicciÃ³n: {str(e)}"

    def _generate_comparison_interpretation(self, comparison_data: Dict[str, Any], user_input: str) -> str:
        """Generar interpretaciÃ³n detallada de la comparaciÃ³n de modelos"""
        try:
            response = f"""
            <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #7b1fa2; color: #000000;">
            
            ## ğŸ” AnÃ¡lisis Detallado de ComparaciÃ³n de Modelos
            
            **Consulta:** "{user_input}"
            
            ### ğŸ† Resultado de la ComparaciÃ³n
            
            BasÃ¡ndome en los datos de rendimiento, he evaluado los siguientes modelos de Machine Learning:
            
            """
            
            # Si hay datos especÃ­ficos de comparaciÃ³n, usarlos
            if comparison_data and 'models' in comparison_data:
                for model_name, metrics in comparison_data['models'].items():
                    response += f"""
            **ğŸ¤– {model_name.title()}:**
            - RÂ² Score: {metrics.get('r2', 0):.3f}
            - MSE: {metrics.get('mse', 0):.3f}  
            - MAE: {metrics.get('mae', 0):.3f}
            """
            
            response += """
            
            ### ğŸ“Š Â¿QuÃ© significan estas mÃ©tricas?
            
            **RÂ² Score (Coeficiente de DeterminaciÃ³n):**
            - ğŸ“ˆ Mide quÃ© tan bien explica el modelo la variabilidad de tus datos
            - ğŸ¯ Rango: 0.0 (malo) a 1.0 (perfecto)
            - âœ… **Mayor RÂ² = Mejor capacidad predictiva**
            
            **MSE (Error CuadrÃ¡tico Medio):**
            - ğŸ“‰ Penaliza mÃ¡s los errores grandes
            - ğŸ¯ **Menor MSE = Mayor precisiÃ³n**
            
            **MAE (Error Absoluto Medio):**
            - ğŸ“Š Error promedio en tÃ©rminos absolutos
            - ğŸ¯ **Menor MAE = Predicciones mÃ¡s cercanas**
            
            ### ğŸ’¡ RecomendaciÃ³n para tu Negocio
            
            <div style="background-color: #f3e5f5; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #9c27b0; color: #4a148c; font-weight: 600;">
            ğŸš€ **Usa el modelo con mayor RÂ²** para tus predicciones futuras
            </div>
            
            ### ğŸ¯ GuÃ­a de SelecciÃ³n por Caso de Uso
            
            - **Linear**: âš¡ Ideal para tendencias simples y respuesta rÃ¡pida
            - **Polynomial**: ğŸ”„ Mejor para patrones con curvas y estacionalidad
            - **Random Forest**: ğŸ¯ MÃ¡xima precisiÃ³n para datos complejos
            
            ### ğŸ“‹ PrÃ³ximos Pasos Sugeridos
            
            1. **ğŸ“Š Implementar** el modelo recomendado en tus predicciones
            2. **ğŸ”„ Monitorear** la precisiÃ³n en datos reales durante 2 semanas
            3. **ğŸ“ˆ Re-evaluar** mensualmente con datos nuevos
            4. **ğŸ¯ Ajustar** si la precisiÃ³n baja del 80%
            
            </div>
            """
            
            return response
            
        except Exception as e:
            return f"Error generando interpretaciÃ³n de comparaciÃ³n: {str(e)}"

    def _handle_model_comparison(self, user_input: str) -> str:
        """Manejar comparaciÃ³n de modelos con fallback inteligente"""
        try:
            # Intentar obtener comparaciÃ³n del backend
            comparison_id = f"comp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            response = requests.get(
                f"{self.backend_url}/api/predict/models/comparison/{comparison_id}",
                timeout=5  # Timeout corto
            )
            
            if response.status_code == 200:
                comparison_data = response.json()
                
                # Guardar resultado para contexto futuro
                self._save_tool_result('comparison', comparison_data, user_input)
                
                return self._generate_comparison_interpretation(comparison_data, user_input)
            else:
                # Si falla el backend, generar comparaciÃ³n simulada
                return self._generate_demo_comparison(user_input)
                
        except Exception as e:
            logger.warning(f"Error en comparaciÃ³n del backend: {e}")
            return self._generate_demo_comparison(user_input)

    def _generate_demo_comparison(self, user_input: str) -> str:
        """Generar comparaciÃ³n de modelos simulada"""
        import numpy as np
        
        # Datos simulados de comparaciÃ³n
        models_comparison = {
            'linear': {
                'mse': np.random.uniform(0.15, 0.25),
                'r2': np.random.uniform(0.75, 0.85),
                'mae': np.random.uniform(0.12, 0.18),
                'speed': 'Muy rÃ¡pido',
                'complexity': 'Baja'
            },
            'polynomial': {
                'mse': np.random.uniform(0.10, 0.20),
                'r2': np.random.uniform(0.80, 0.90),
                'mae': np.random.uniform(0.08, 0.15),
                'speed': 'Moderado',
                'complexity': 'Media'
            },
            'random_forest': {
                'mse': np.random.uniform(0.08, 0.15),
                'r2': np.random.uniform(0.85, 0.95),
                'mae': np.random.uniform(0.06, 0.12),
                'speed': 'Lento',
                'complexity': 'Alta'
            }
        }
        
        # Encontrar el mejor modelo por RÂ²
        best_model = max(models_comparison.keys(), key=lambda k: models_comparison[k]['r2'])
        
        # Guardar resultados en el contexto
        comparison_result = {
            'best_model': best_model.replace('_', ' ').title(),
            'r2_scores': {k: v['r2'] for k, v in models_comparison.items()},
            'models_data': models_comparison,
            'conclusion': f"{best_model.replace('_', ' ').title()} es el mÃ¡s preciso"
        }
        self._save_tool_result('comparison', comparison_result, user_input)
        
        interpretation = f"""
        <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #e0e0e0; color: #000000;">
        
        ## ğŸ” ComparaciÃ³n de Modelos de ML
        
        **BasÃ¡ndome en tu consulta:** "{user_input}"
        
        ### ğŸ† Modelo Recomendado: **{best_model.replace('_', ' ').title()}**
        
        ### ğŸ“Š Resultados Detallados
        
        """
        
        for model, metrics in models_comparison.items():
            model_name = model.replace('_', ' ').title()
            r2_color = "#1b5e20" if metrics['r2'] > 0.85 else "#f57c00" if metrics['r2'] > 0.75 else "#d32f2f"
            
            interpretation += f"""
        **ğŸ¤– {model_name}:**
        - **RÂ² Score**: <span style="color: {r2_color}; font-weight: bold; background-color: #f5f5f5; padding: 2px 6px; border-radius: 4px;">{metrics['r2']:.3f}</span>
        - **MSE**: <span style="color: #000000; font-weight: bold;">{metrics['mse']:.3f}</span>
        - **MAE**: <span style="color: #000000; font-weight: bold;">{metrics['mae']:.3f}</span>
        - **Velocidad**: <span style="color: #4a148c; font-weight: bold;">{metrics['speed']}</span>
        - **Complejidad**: <span style="color: #4a148c; font-weight: bold;">{metrics['complexity']}</span>
        
        """
        
        interpretation += f"""
        ### ğŸ’¡ Recomendaciones
        
        <div style="background-color: #e8f5e8; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #4caf50; color: #1b5e20; font-weight: 600;">
        ğŸ¯ **Mejor opciÃ³n:** {best_model.replace('_', ' ').title()} con RÂ² de {models_comparison[best_model]['r2']:.3f}
        </div>
        
        <div style="background-color: #f3e5f5; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #9c27b0; color: #4a148c; font-weight: 600;">
        ğŸ“ˆ **Criterio de selecciÃ³n:** Mayor RÂ² indica mejor capacidad predictiva
        </div>
        
        ### ğŸ“‹ GuÃ­a de SelecciÃ³n:
        - **Linear**: Ideal para tendencias simples y predicciones rÃ¡pidas
        - **Polynomial**: Mejor para patrones mÃ¡s complejos
        - **Random Forest**: MÃ¡xima precisiÃ³n para datos complejos
        
        </div>
        """
        
        return interpretation
    
    def _handle_analysis_request(self, user_input: str) -> str:
        """Manejar solicitud de anÃ¡lisis con capacidades mejoradas"""
        
        # Extraer informaciÃ³n de la consulta
        category = self._extract_category_from_input(user_input)
        
        if category:
            return self._generate_category_analysis(category, user_input)
        else:
            return self._generate_general_analysis(user_input)
    
    def _extract_category_from_input(self, user_input: str) -> str:
        """Extraer categorÃ­a de producto del input del usuario"""
        user_input_lower = user_input.lower()
        
        categories = {
            'electronica': ['electronica', 'electronics', 'computadora', 'telefono', 'gadget'],
            'ropa': ['ropa', 'clothing', 'vestimenta', 'textil', 'fashion'],
            'comida': ['comida', 'food', 'alimento', 'bebida', 'restaurant'],
            'hogar': ['hogar', 'casa', 'home', 'domestico'],
            'deportes': ['deporte', 'sport', 'fitness', 'ejercicio'],
            'salud': ['salud', 'health', 'medicina', 'farmacia'],
            'belleza': ['belleza', 'beauty', 'cosmÃ©tico', 'cuidado personal']
        }
        
        for category, keywords in categories.items():
            if any(keyword in user_input_lower for keyword in keywords):
                return category
        
        return 'general'

    def _generate_category_analysis(self, category: str, user_input: str) -> str:
        """Generar anÃ¡lisis especÃ­fico por categorÃ­a"""
        import numpy as np
        
        # Generar datos simulados para la categorÃ­a
        np.random.seed(hash(category) % 1000)
        
        # Simular tendencias de los Ãºltimos 6 meses
        months = ['Enero', 'Febrero', 'Marzo', 'Abril', 'Mayo', 'Junio']
        base_sales = 1000 + hash(category) % 500
        
        monthly_data = []
        for i, month in enumerate(months):
            # Tendencia creciente con variaciÃ³n
            trend_factor = 1 + (i * 0.1) + np.random.uniform(-0.05, 0.05)
            sales = int(base_sales * trend_factor)
            monthly_data.append({'month': month, 'sales': sales})
        
        # Calcular insights
        total_sales = sum(data['sales'] for data in monthly_data)
        avg_growth = (monthly_data[-1]['sales'] - monthly_data[0]['sales']) / monthly_data[0]['sales'] * 100
        
        response = f"""
        <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #ff9800; color: #000000;">
        
        ## ğŸ“ˆ AnÃ¡lisis de Tendencias - CategorÃ­a: {category.title()}
        
        **ğŸ“ Modo Demo**: Datos simulados para demostraciÃ³n
        
        ### ğŸ“Š Resumen Ejecutivo
        
        <div style="background-color: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #ff9800; color: #e65100; font-weight: 600;">
        ğŸ“ˆ **Crecimiento promedio:** {avg_growth:.1f}% en los Ãºltimos 6 meses
        </div>
        
        ### ğŸ“… Tendencias Mensuales Recientes
        
        """
        
        for data in monthly_data[-3:]:  # Ãšltimos 3 meses
            response += f"- **{data['month']}**: {data['sales']:,} unidades vendidas\n"
        
        response += f"""
        
        ### ğŸ’¡ Insights Clave para {category.title()}
        
        - ğŸ¯ **Demanda estacional**: {category.title()} muestra patrones predecibles
        - ğŸ“Š **Volumen total**: {total_sales:,} unidades en 6 meses  
        - ğŸ”„ **Estrategia**: {"ğŸ“ˆ Aumentar inventario - tendencia creciente" if avg_growth > 5 else "ğŸ“Š Mantener niveles actuales - demanda estable"}
        - ğŸ’° **Oportunidad**: {"Alto potencial de crecimiento" if avg_growth > 10 else "Mercado estable y confiable"}
        
        ### ğŸš€ Recomendaciones EspecÃ­ficas
        
        1. **ğŸ“Š Stock Ã³ptimo**: {int(monthly_data[-1]['sales'] * 1.3):,} unidades (30% buffer)
        2. **ğŸ¯ Punto de reorden**: {int(monthly_data[-1]['sales'] * 0.4):,} unidades  
        3. **ğŸ“… PrÃ³xima revisiÃ³n**: En 2 semanas
        4. **ï¿½ Monitoreo**: Tendencias semanales por subcategorÃ­a
        
        ### ğŸ¤– Â¿Necesitas algo mÃ¡s especÃ­fico?
        
        Puedo ayudarte con:
        - ğŸ“Š **PredicciÃ³n especÃ­fica**: "Predice la demanda para el producto X"
        - ï¿½ **Comparar modelos**: "Â¿QuÃ© modelo es mÃ¡s preciso?"
        - ğŸ“ˆ **AnÃ¡lisis detallado**: "Analiza otra categorÃ­a"
        
        </div>
        """
        
        # Guardar en contexto
        analysis_data = {
            'analysis_type': 'category_trends',
            'category': category,
            'insights': [
                f"Crecimiento del {avg_growth:.1f}% en 6 meses",
                f"Volumen total: {total_sales:,} unidades",
                "Patrones estacionales detectados"
            ]
        }
        self._save_tool_result('analysis', analysis_data, user_input)
        
        return response

    def _generate_general_analysis(self, user_input: str) -> str:
        """Generar anÃ¡lisis general cuando no se detecta categorÃ­a especÃ­fica"""
        
        response = f"""
        <div style="background-color: #ffffff; padding: 20px; border-radius: 12px; border: 2px solid #9c27b0; color: #000000;">
        
        ## ğŸ” AnÃ¡lisis General de Tendencias
        
        **Tu consulta:** "{user_input}"
        
        ### ğŸ“Š Insights Disponibles
        
        Para brindarte un anÃ¡lisis mÃ¡s especÃ­fico, puedo ayudarte con:
        
        **Por CategorÃ­a:**
        - ğŸ‘• Ropa y Fashion
        - ğŸ’» ElectrÃ³nicos
        - ğŸ• Alimentos y Bebidas
        - ğŸ  Hogar y DecoraciÃ³n
        - ğŸ’ª Deportes y Fitness
        
        **Por Producto:**
        - ğŸ“Š Predicciones especÃ­ficas
        - ğŸ“ˆ AnÃ¡lisis de tendencias histÃ³ricas
        - ğŸ” ComparaciÃ³n con competencia
        
        ### ğŸ’¡ RecomendaciÃ³n
        
        <div style="background-color: #f3e5f5; padding: 15px; border-radius: 8px; margin: 15px 0; border: 2px solid #9c27b0; color: #4a148c; font-weight: 600;">
        ğŸ¯ **Especifica una categorÃ­a** para obtener insights mÃ¡s detallados
        </div>
        
        **Ejemplos de consultas mÃ¡s especÃ­ficas:**
        - "Analiza las tendencias de ropa"
        - "Â¿CÃ³mo estÃ¡ el mercado de electrÃ³nicos?"
        - "Tendencias en comida rÃ¡pida"
        
        </div>
        """
        
        return response

    def _extract_category_from_input(self, user_input: str) -> str:
        """Extraer categorÃ­a del input del usuario"""
        user_input_lower = user_input.lower()
        
        categories = {
            'electrÃ³nicos': ['electronico', 'electronica', 'electronic', 'tecnologia'],
            'ropa': ['ropa', 'vestimenta', 'clothing', 'textil'],
            'alimentaciÃ³n': ['alimento', 'comida', 'food', 'bebida'],
            'hogar': ['hogar', 'casa', 'home', 'domestico'],
            'deportes': ['deporte', 'sport', 'fitness', 'ejercicio'],
            'salud': ['salud', 'health', 'medicina', 'farmacia'],
            'belleza': ['belleza', 'beauty', 'cosmetico', 'maquillaje']
        }
        
        for category, keywords in categories.items():
            if any(keyword in user_input_lower for keyword in keywords):
                return category
        
        return None

    def _generate_category_analysis